# Treasure Hunt AI ğŸ—ºï¸ğŸ¤–

A grid-based **Treasure Hunt Game** where two AI agentsâ€”**DQN Agent** and **Minimax Agent**â€”compete to collect treasures while avoiding guards. The project is implemented using **Pygame** and **PyTorch**.

---

## Features ğŸš€

- **Dynamic Gameplay**: Two AI agents navigate the grid to collect treasures.
- **DQN Agent**: Trained using Deep Q-Learning with replay memory.
- **Minimax Agent**: Uses the minimax algorithm to plan its moves.
- **Obstacles and Guards**: Both agents must avoid guards to survive.
- **Scoring System**: Tracks the performance of both agents.
- **Customizable Parameters**: Number of treasures, guards, grid size, and turns.

---

## Requirements ğŸ“¦

- Python 3.7+
- Libraries: 
  - `torch`
  - `pygame`

---

## Installation ğŸ› ï¸

1. **Clone the repository**:

   ```bash
   git clone https://github.com/your-username/TreasureHuntDualAI.git
   cd treasure-hunt-dqn-minimax
   ```

2. **Install dependencies**:
   Use `pip` to install the required Python packages:

   ```bash
   pip install -r requirements.txt
   ```

## How to Run ğŸƒâ€â™‚ï¸

### Run the Game
To play/watch the game, run:

```bash
python main.py
```

* The **DQN Agent** (trained model) will compete with the **Minimax Agent**.
* Results, including scores and game logs, will be displayed in the terminal and saved in `logs/game_stats.txt`.

### Retrain the DQN Agent
To retrain the DQN Agent:

```bash
python models/dqn_training.py
```

* Training logs are saved in `logs/training_log.txt`.
* The trained model is automatically saved for future gameplay.

## Game Rules ğŸ•¹ï¸

1. **Objective**: Collect as many treasures as possible.
2. **Guards**:
   * If an agent collides with a guard, it loses the game immediately.
3. **Treasure Collection**:
   * Agents collect treasures for points. The agent with the highest score wins.
4. **Turns**:
   * The game ends after a fixed number of turns (configurable).

## File Structure ğŸ“‚

```
TreasureHuntDualAI/
â”œâ”€â”€ main.py                 # Main script to run the game
â”œâ”€â”€ agents/                 # AI agent implementations
â”‚   â”œâ”€â”€ __init__.py         # Init file for the agents package
â”‚   â”œâ”€â”€ dqn_agent.py        # DQN agent implementation
â”‚   â”œâ”€â”€ minimax_agent.py    # Minimax agent implementation
â”œâ”€â”€ environment/            # Game environment and logic
â”‚   â”œâ”€â”€ __init__.py         # Init file for the environment package
â”‚   â”œâ”€â”€ constants.py        # Game-related constants
â”‚   â”œâ”€â”€ game_environment.py # Core game environment logic
â”‚   â”œâ”€â”€ pygame_visualizer.py# Pygame-based game visualization
â”œâ”€â”€ logs/                   # Logs directory
â”‚   â”œâ”€â”€ dqn_training.txt    # Logs for DQN training progress
â”‚   â”œâ”€â”€ game_stats.txt      # Logs for game outcomes and scores
â”œâ”€â”€ models/                 # DQN model training and management
â”‚   â”œâ”€â”€ __init__.py         # Init file for the models package
â”‚   â”œâ”€â”€ dqn_training.py     # Training script for the DQN agent
â”œâ”€â”€ saved_models/           # Directory for saving trained DQN models
â”‚   â”œâ”€â”€ final_dqn_model.pth # Trained DQN model checkpoint
â”œâ”€â”€ utils/                  # Utility scripts
â”‚   â”œâ”€â”€ __init__.py         # Init file for the utils package
â”‚   â”œâ”€â”€ helpers.py          # Helper functions for game logic
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ requirements.txt        # Packages required for the project
â””â”€â”€ .gitignore              # Git configuration to exclude unnecessary files
```

## Customization âš™ï¸

You can customize the game settings in the `treasure_hunt.py` file:
* **Grid Size**: Change the `GRID_SIZE` variable.
* **Number of Treasures and Guards**: Adjust `NUM_TREASURES` and `NUM_GUARDS`.
* **Max Turns**: Modify the `NUM_TURNS` variable.

## Example Gameplay ğŸ®

* **DQN Agent** vs. **Minimax Agent** on a 10x10 grid.
* **Treasures**: 6
* **Guards**: 3
* **Turns**: 50

## Results ğŸ“Š

* After training, the **DQN Agent** learns to avoid guards and optimize treasure collection.
* Training results are logged in `training_log.txt`.

## Future Improvements ğŸŒŸ

* Add player vs. AI mode for interactive gameplay.
* Implement more advanced reinforcement learning algorithms (e.g., PPO, A3C).
* Introduce different types of obstacles and rewards.

## Contributing ğŸ¤

Feel free to submit pull requests or open issues to improve the project!

## License ğŸ“œ

This project is licensed under the MIT License.

## Credits ğŸ™Œ

Created by **Varun Raskar**. Special thanks to the creators of PyTorch and Pygame!

### Steps for Usage:
1. Copy the entire content above into a README.md file.
2. Replace the placeholder **your-username** and the repository URL with your details.
3. Commit and push it to your GitHub repository. ğŸ‰